{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "    <h1 align=\"center\"> Handwritten digit dataset in Farsi & English</h1> \n",
    "     <h1 align=\"center\">   Image classification </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Farsi digits\n",
    "\n",
    "\n",
    "Although Farsi is a right to left script, its digits are written from left to righ. HODA dataset has 102,352 digits which extracted from about 12,000 registration forms. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/digit.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install scikit-image   # install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is written with Matlab, one can load it with \"scipy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "dataset = io.loadmat('./dataset/Data_hoda_full.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set has 60,000 digit for Training set and 20,000 digits for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and training set split\n",
    "X_train_orginal = np.squeeze(dataset['Data'][:10000])\n",
    "y_train = np.squeeze(dataset['labels'][:10000])\n",
    "X_test_original = np.squeeze(dataset['Data'][10000:12000])\n",
    "y_test = np.squeeze(dataset['labels'][10000:12000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"squeeze\": Remove single-dimensional entries from the shape of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_orginal[400], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of 9000th image is: 9\n"
     ]
    }
   ],
   "source": [
    "i=9000\n",
    "image = X_train_orginal[i]\n",
    "label = y_train[i]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "print(\"Label of {}th image is: {}\".format(i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize the image from ** to (5,5)\n",
    "X_train_5by5 = [resize(img, (5, 5)) for img in X_train_orginal]\n",
    "X_test_5by_5 = [resize(img, (5, 5)) for img in X_test_original]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train_5by5[1]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "X_train = [x.reshape(25) for x in X_train_5by5]\n",
    "X_test = [x.reshape(25) for x in X_test_5by_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n_neighbor is a hyperparameter which needs to be tuned.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions and Evaluations\n",
    "\n",
    "Let's evaluate our **KNN** model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 24 is a 2, and you prediction is: 2.\n"
     ]
    }
   ],
   "source": [
    "sample = 24\n",
    "\n",
    "X = [X_test[sample]]\n",
    "\n",
    "predicted_class = neigh.predict(X)\n",
    "actual_class = y_test[sample]\n",
    "\n",
    "print (\"Sample {} is a {}, and you prediction is: {}.\".format(sample, actual_class, predicted_class[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(neigh.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes is:\n",
      "[5 8 8 ... 6 8 5]\n",
      "==========================================================================\n",
      "True classes is:\n",
      "[5 8 8 ... 6 8 5]\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Predicted classes is:\")\n",
    "print(y_pred)\n",
    "print(\"==========================================================================\")\n",
    "print(\"True classes is:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 96.350 %\n"
     ]
    }
   ],
   "source": [
    "acc = neigh.score(X_test, y_test)\n",
    "print (\"Accuracy is %.3f %%\" %(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216   9   0   0   0   1   0   1   0   0]\n",
      " [  3 187   1   0   0   0   0   0   0   0]\n",
      " [  0   0 189  11   4   0   1   1   0   1]\n",
      " [  0   0   0 166  20   1   0   0   0   0]\n",
      " [  0   0   0   3 176   1   0   0   0   0]\n",
      " [  0   0   0   0   0 181   1   0   0   0]\n",
      " [  0   0   0   0   0   0 206   0   0   6]\n",
      " [  1   0   2   0   0   0   0 204   0   0]\n",
      " [  0   0   0   0   0   1   0   0 202   0]\n",
      " [  0   1   0   0   0   0   1   0   2 200]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that that after arouns K>4 the error rate just tends to hover around 0.02 Let's retrain the model with that and check the classification report! K=4 is the minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=4\n",
      "\n",
      "\n",
      "[[217   2   0   0   0   0   0   1   0   0]\n",
      " [  5 191   0   0   0   0   0   0   0   1]\n",
      " [  0   1 188   1   0   0   0   2   0   0]\n",
      " [  0   0   6 171   3   0   0   0   0   0]\n",
      " [  0   0   3  12 185   0   0   0   0   0]\n",
      " [  1   0   0   0   1 181   1   0   1   0]\n",
      " [  0   0   1   0   0   1 206   0   0   1]\n",
      " [  1   0   0   0   0   0   0 205   0   0]\n",
      " [  0   0   0   0   0   0   1   0 201   2]\n",
      " [  0   0   1   0   0   0   4   0   0 202]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       220\n",
      "           1       0.98      0.97      0.98       197\n",
      "           2       0.94      0.98      0.96       192\n",
      "           3       0.93      0.95      0.94       180\n",
      "           4       0.98      0.93      0.95       200\n",
      "           5       0.99      0.98      0.99       185\n",
      "           6       0.97      0.99      0.98       209\n",
      "           7       0.99      1.00      0.99       206\n",
      "           8       1.00      0.99      0.99       204\n",
      "           9       0.98      0.98      0.98       207\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOW WITH K=4\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=4')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,  Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54941176, 0.48784314, 0.0172549 , 0.14980392, 0.48196078,\n",
       "       0.79176471, 0.2627451 , 0.40862745, 0.72117647, 0.3172549 ,\n",
       "       0.38235294, 0.65686275, 0.8627451 , 0.27058824, 0.00980392,\n",
       "       0.02235294, 0.62313725, 0.41960784, 0.00862745, 0.        ,\n",
       "       0.06901961, 0.69058824, 0.09843137, 0.        , 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(x_train, y_train, x_test, y_test):\n",
    "    #Check data Type\n",
    "    print (\"\\ttype(x_train): {}\".format(type(x_train)))\n",
    "    print (\"\\ttype(y_train): {}\".format(type(y_train)))\n",
    "\n",
    "    #check data Shape\n",
    "    print (\"\\tx_train.shape: {}\".format(np.shape(x_train)))\n",
    "    print (\"\\ty_train.shape: {}\".format(np.shape(y_train)))\n",
    "    print (\"\\tx_test.shape: {}\".format(np.shape(x_test)))\n",
    "    print (\"\\ty_test.shape: {}\".format(np.shape(y_test)))\n",
    "\n",
    "    #sample data\n",
    "    print (\"\\ty_train[0]: {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data for Keras. \n",
    "x_train = np.array(X_train)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "x_test = np.array(X_test)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing:\n",
      "\ttype(x_train): <class 'list'>\n",
      "\ttype(y_train): <class 'numpy.ndarray'>\n",
      "\tx_train.shape: (10000, 25)\n",
      "\ty_train.shape: (10000, 10)\n",
      "\tx_test.shape: (2000, 25)\n",
      "\ty_test.shape: (2000, 10)\n",
      "\ty_train[0]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "After Preprocessing:\n",
      "\ttype(x_train): <class 'list'>\n",
      "\ttype(y_train): <class 'numpy.ndarray'>\n",
      "\tx_train.shape: (10000, 25)\n",
      "\ty_train.shape: (10000, 10)\n",
      "\tx_test.shape: (2000, 25)\n",
      "\ty_test.shape: (2000, 10)\n",
      "\ty_train[0]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Preprocessing:\")\n",
    "print_data_info(X_train, y_train, X_test, y_test)\n",
    "print(\"After Preprocessing:\")\n",
    "print_data_info(X_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1664      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,314\n",
      "Trainable params: 2,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 1.4295 - accuracy: 0.7126 - val_loss: 1.4243 - val_accuracy: 0.7070\n",
      "Epoch 2/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.4046 - accuracy: 0.7157 - val_loss: 1.4014 - val_accuracy: 0.7010\n",
      "Epoch 3/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.3810 - accuracy: 0.7179 - val_loss: 1.3782 - val_accuracy: 0.7085\n",
      "Epoch 4/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.3575 - accuracy: 0.7230 - val_loss: 1.3545 - val_accuracy: 0.7125\n",
      "Epoch 5/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 1.3354 - accuracy: 0.7259 - val_loss: 1.3342 - val_accuracy: 0.7135\n",
      "Epoch 6/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 1.3141 - accuracy: 0.7259 - val_loss: 1.3112 - val_accuracy: 0.7265\n",
      "Epoch 7/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.2933 - accuracy: 0.7301 - val_loss: 1.2904 - val_accuracy: 0.7240\n",
      "Epoch 8/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.2728 - accuracy: 0.7339 - val_loss: 1.2700 - val_accuracy: 0.7260\n",
      "Epoch 9/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.2538 - accuracy: 0.7344 - val_loss: 1.2507 - val_accuracy: 0.7260\n",
      "Epoch 10/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.2351 - accuracy: 0.7410 - val_loss: 1.2326 - val_accuracy: 0.7305\n",
      "Epoch 11/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.2165 - accuracy: 0.7409 - val_loss: 1.2134 - val_accuracy: 0.7250\n",
      "Epoch 12/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 1.1991 - accuracy: 0.7406 - val_loss: 1.1965 - val_accuracy: 0.7260\n",
      "Epoch 13/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 1.1815 - accuracy: 0.7490 - val_loss: 1.1822 - val_accuracy: 0.7350\n",
      "Epoch 14/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.1645 - accuracy: 0.7462 - val_loss: 1.1616 - val_accuracy: 0.7350\n",
      "Epoch 15/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.1477 - accuracy: 0.7536 - val_loss: 1.1460 - val_accuracy: 0.7350\n",
      "Epoch 16/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.1320 - accuracy: 0.7538 - val_loss: 1.1285 - val_accuracy: 0.7370\n",
      "Epoch 17/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.1164 - accuracy: 0.7586 - val_loss: 1.1153 - val_accuracy: 0.7375\n",
      "Epoch 18/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 1.1014 - accuracy: 0.7604 - val_loss: 1.0993 - val_accuracy: 0.7415\n",
      "Epoch 19/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0863 - accuracy: 0.7602 - val_loss: 1.0845 - val_accuracy: 0.7540\n",
      "Epoch 20/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0724 - accuracy: 0.7638 - val_loss: 1.0715 - val_accuracy: 0.7490\n",
      "Epoch 21/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0578 - accuracy: 0.7679 - val_loss: 1.0557 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0433 - accuracy: 0.7706 - val_loss: 1.0442 - val_accuracy: 0.7445\n",
      "Epoch 23/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0301 - accuracy: 0.7679 - val_loss: 1.0272 - val_accuracy: 0.7590\n",
      "Epoch 24/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0165 - accuracy: 0.7746 - val_loss: 1.0131 - val_accuracy: 0.7645\n",
      "Epoch 25/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 1.0036 - accuracy: 0.7755 - val_loss: 1.0016 - val_accuracy: 0.7595\n",
      "Epoch 26/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.9910 - accuracy: 0.7778 - val_loss: 0.9901 - val_accuracy: 0.7585\n",
      "Epoch 27/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.9783 - accuracy: 0.7786 - val_loss: 0.9749 - val_accuracy: 0.7660\n",
      "Epoch 28/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.9662 - accuracy: 0.7805 - val_loss: 0.9641 - val_accuracy: 0.7685\n",
      "Epoch 29/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.9541 - accuracy: 0.7843 - val_loss: 0.9515 - val_accuracy: 0.7725\n",
      "Epoch 30/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.9425 - accuracy: 0.7839 - val_loss: 0.9387 - val_accuracy: 0.7710\n",
      "Epoch 31/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.9310 - accuracy: 0.7850 - val_loss: 0.9272 - val_accuracy: 0.7795\n",
      "Epoch 32/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.9188 - accuracy: 0.7876 - val_loss: 0.9157 - val_accuracy: 0.7855\n",
      "Epoch 33/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.9083 - accuracy: 0.7936 - val_loss: 0.9056 - val_accuracy: 0.7800\n",
      "Epoch 34/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8969 - accuracy: 0.7904 - val_loss: 0.8942 - val_accuracy: 0.7855\n",
      "Epoch 35/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8866 - accuracy: 0.7949 - val_loss: 0.8833 - val_accuracy: 0.7810\n",
      "Epoch 36/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8756 - accuracy: 0.7970 - val_loss: 0.8725 - val_accuracy: 0.7880\n",
      "Epoch 37/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8649 - accuracy: 0.7972 - val_loss: 0.8621 - val_accuracy: 0.7870\n",
      "Epoch 38/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8547 - accuracy: 0.7975 - val_loss: 0.8512 - val_accuracy: 0.7900\n",
      "Epoch 39/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8455 - accuracy: 0.8019 - val_loss: 0.8437 - val_accuracy: 0.7880\n",
      "Epoch 40/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8351 - accuracy: 0.7994 - val_loss: 0.8315 - val_accuracy: 0.7950\n",
      "Epoch 41/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8252 - accuracy: 0.8052 - val_loss: 0.8226 - val_accuracy: 0.7955\n",
      "Epoch 42/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8157 - accuracy: 0.8044 - val_loss: 0.8117 - val_accuracy: 0.8000\n",
      "Epoch 43/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.8066 - accuracy: 0.8071 - val_loss: 0.8037 - val_accuracy: 0.7985\n",
      "Epoch 44/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7972 - accuracy: 0.8071 - val_loss: 0.7946 - val_accuracy: 0.8000\n",
      "Epoch 45/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7884 - accuracy: 0.8104 - val_loss: 0.7853 - val_accuracy: 0.8055\n",
      "Epoch 46/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7800 - accuracy: 0.8114 - val_loss: 0.7754 - val_accuracy: 0.8090\n",
      "Epoch 47/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7713 - accuracy: 0.8138 - val_loss: 0.7676 - val_accuracy: 0.8085\n",
      "Epoch 48/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7620 - accuracy: 0.8146 - val_loss: 0.7586 - val_accuracy: 0.8130\n",
      "Epoch 49/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7533 - accuracy: 0.8146 - val_loss: 0.7517 - val_accuracy: 0.8110\n",
      "Epoch 50/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7453 - accuracy: 0.8145 - val_loss: 0.7411 - val_accuracy: 0.8180\n",
      "Epoch 51/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.7371 - accuracy: 0.8199 - val_loss: 0.7328 - val_accuracy: 0.8210\n",
      "Epoch 52/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7300 - accuracy: 0.8216 - val_loss: 0.7272 - val_accuracy: 0.8135\n",
      "Epoch 53/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.7217 - accuracy: 0.8210 - val_loss: 0.7172 - val_accuracy: 0.8205\n",
      "Epoch 54/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.7147 - accuracy: 0.8223 - val_loss: 0.7092 - val_accuracy: 0.8230\n",
      "Epoch 55/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.7068 - accuracy: 0.8245 - val_loss: 0.7028 - val_accuracy: 0.8220\n",
      "Epoch 56/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6994 - accuracy: 0.8254 - val_loss: 0.6942 - val_accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6918 - accuracy: 0.8282 - val_loss: 0.6883 - val_accuracy: 0.8245\n",
      "Epoch 58/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.6852 - accuracy: 0.8282 - val_loss: 0.6802 - val_accuracy: 0.8295\n",
      "Epoch 59/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6774 - accuracy: 0.8313 - val_loss: 0.6732 - val_accuracy: 0.8280\n",
      "Epoch 60/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6712 - accuracy: 0.8342 - val_loss: 0.6673 - val_accuracy: 0.8310\n",
      "Epoch 61/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6643 - accuracy: 0.8330 - val_loss: 0.6600 - val_accuracy: 0.8325\n",
      "Epoch 62/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6572 - accuracy: 0.8356 - val_loss: 0.6535 - val_accuracy: 0.8320\n",
      "Epoch 63/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6513 - accuracy: 0.8375 - val_loss: 0.6477 - val_accuracy: 0.8325\n",
      "Epoch 64/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6451 - accuracy: 0.8359 - val_loss: 0.6400 - val_accuracy: 0.8395\n",
      "Epoch 65/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6381 - accuracy: 0.8399 - val_loss: 0.6354 - val_accuracy: 0.8345\n",
      "Epoch 66/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6324 - accuracy: 0.8394 - val_loss: 0.6279 - val_accuracy: 0.8375\n",
      "Epoch 67/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6263 - accuracy: 0.8416 - val_loss: 0.6207 - val_accuracy: 0.8430\n",
      "Epoch 68/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6199 - accuracy: 0.8430 - val_loss: 0.6142 - val_accuracy: 0.8465\n",
      "Epoch 69/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6151 - accuracy: 0.8431 - val_loss: 0.6096 - val_accuracy: 0.8405\n",
      "Epoch 70/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.6093 - accuracy: 0.8443 - val_loss: 0.6031 - val_accuracy: 0.8470\n",
      "Epoch 71/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.6033 - accuracy: 0.8454 - val_loss: 0.5976 - val_accuracy: 0.8430\n",
      "Epoch 72/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5977 - accuracy: 0.8472 - val_loss: 0.5914 - val_accuracy: 0.8485\n",
      "Epoch 73/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5923 - accuracy: 0.8464 - val_loss: 0.5865 - val_accuracy: 0.8480\n",
      "Epoch 74/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5868 - accuracy: 0.8478 - val_loss: 0.5813 - val_accuracy: 0.8450\n",
      "Epoch 75/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5817 - accuracy: 0.8487 - val_loss: 0.5750 - val_accuracy: 0.8545\n",
      "Epoch 76/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5766 - accuracy: 0.8508 - val_loss: 0.5701 - val_accuracy: 0.8510\n",
      "Epoch 77/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5716 - accuracy: 0.8524 - val_loss: 0.5674 - val_accuracy: 0.8520\n",
      "Epoch 78/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5667 - accuracy: 0.8508 - val_loss: 0.5590 - val_accuracy: 0.8550\n",
      "Epoch 79/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5608 - accuracy: 0.8531 - val_loss: 0.5545 - val_accuracy: 0.8570\n",
      "Epoch 80/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5568 - accuracy: 0.8547 - val_loss: 0.5523 - val_accuracy: 0.8585\n",
      "Epoch 81/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5527 - accuracy: 0.8555 - val_loss: 0.5458 - val_accuracy: 0.8530\n",
      "Epoch 82/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5476 - accuracy: 0.8554 - val_loss: 0.5400 - val_accuracy: 0.8590\n",
      "Epoch 83/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5427 - accuracy: 0.8571 - val_loss: 0.5386 - val_accuracy: 0.8585\n",
      "Epoch 84/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5391 - accuracy: 0.8564 - val_loss: 0.5313 - val_accuracy: 0.8645\n",
      "Epoch 85/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5340 - accuracy: 0.8575 - val_loss: 0.5277 - val_accuracy: 0.8575\n",
      "Epoch 86/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5306 - accuracy: 0.8591 - val_loss: 0.5220 - val_accuracy: 0.8640\n",
      "Epoch 87/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5257 - accuracy: 0.8612 - val_loss: 0.5198 - val_accuracy: 0.8660\n",
      "Epoch 88/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5213 - accuracy: 0.8606 - val_loss: 0.5144 - val_accuracy: 0.8685\n",
      "Epoch 89/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5176 - accuracy: 0.8618 - val_loss: 0.5099 - val_accuracy: 0.8640\n",
      "Epoch 90/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5129 - accuracy: 0.8622 - val_loss: 0.5054 - val_accuracy: 0.8685\n",
      "Epoch 91/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5093 - accuracy: 0.8619 - val_loss: 0.5021 - val_accuracy: 0.8710\n",
      "Epoch 92/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5055 - accuracy: 0.8651 - val_loss: 0.4970 - val_accuracy: 0.8705\n",
      "Epoch 93/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.5014 - accuracy: 0.8645 - val_loss: 0.4939 - val_accuracy: 0.8750\n",
      "Epoch 94/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4981 - accuracy: 0.8645 - val_loss: 0.4905 - val_accuracy: 0.8730\n",
      "Epoch 95/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4943 - accuracy: 0.8664 - val_loss: 0.4867 - val_accuracy: 0.8730\n",
      "Epoch 96/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4904 - accuracy: 0.8665 - val_loss: 0.4834 - val_accuracy: 0.8765\n",
      "Epoch 97/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4877 - accuracy: 0.8660 - val_loss: 0.4788 - val_accuracy: 0.8755\n",
      "Epoch 98/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4838 - accuracy: 0.8673 - val_loss: 0.4764 - val_accuracy: 0.8760\n",
      "Epoch 99/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4799 - accuracy: 0.8675 - val_loss: 0.4722 - val_accuracy: 0.8790\n",
      "Epoch 100/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4765 - accuracy: 0.8681 - val_loss: 0.4677 - val_accuracy: 0.8770\n",
      "Epoch 101/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4734 - accuracy: 0.8691 - val_loss: 0.4659 - val_accuracy: 0.8780\n",
      "Epoch 102/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4701 - accuracy: 0.8704 - val_loss: 0.4616 - val_accuracy: 0.8810\n",
      "Epoch 103/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4670 - accuracy: 0.8711 - val_loss: 0.4580 - val_accuracy: 0.8795\n",
      "Epoch 104/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4633 - accuracy: 0.8730 - val_loss: 0.4553 - val_accuracy: 0.8795\n",
      "Epoch 105/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4601 - accuracy: 0.8726 - val_loss: 0.4513 - val_accuracy: 0.8835\n",
      "Epoch 106/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4575 - accuracy: 0.8729 - val_loss: 0.4494 - val_accuracy: 0.8810\n",
      "Epoch 107/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4544 - accuracy: 0.8748 - val_loss: 0.4454 - val_accuracy: 0.8825\n",
      "Epoch 108/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4516 - accuracy: 0.8741 - val_loss: 0.4437 - val_accuracy: 0.8835\n",
      "Epoch 109/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4487 - accuracy: 0.8752 - val_loss: 0.4408 - val_accuracy: 0.8835\n",
      "Epoch 110/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4452 - accuracy: 0.8759 - val_loss: 0.4376 - val_accuracy: 0.8865\n",
      "Epoch 111/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4433 - accuracy: 0.8773 - val_loss: 0.4329 - val_accuracy: 0.8835\n",
      "Epoch 112/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4395 - accuracy: 0.8750 - val_loss: 0.4319 - val_accuracy: 0.8865\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4372 - accuracy: 0.8764 - val_loss: 0.4292 - val_accuracy: 0.8860\n",
      "Epoch 114/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4344 - accuracy: 0.8784 - val_loss: 0.4263 - val_accuracy: 0.8895\n",
      "Epoch 115/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4320 - accuracy: 0.8785 - val_loss: 0.4221 - val_accuracy: 0.8890\n",
      "Epoch 116/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4293 - accuracy: 0.8790 - val_loss: 0.4224 - val_accuracy: 0.8890\n",
      "Epoch 117/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4261 - accuracy: 0.8791 - val_loss: 0.4181 - val_accuracy: 0.8910\n",
      "Epoch 118/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4239 - accuracy: 0.8791 - val_loss: 0.4162 - val_accuracy: 0.8935\n",
      "Epoch 119/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4218 - accuracy: 0.8804 - val_loss: 0.4125 - val_accuracy: 0.8890\n",
      "Epoch 120/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4190 - accuracy: 0.8817 - val_loss: 0.4105 - val_accuracy: 0.8915\n",
      "Epoch 121/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4163 - accuracy: 0.8806 - val_loss: 0.4078 - val_accuracy: 0.8945\n",
      "Epoch 122/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4142 - accuracy: 0.8817 - val_loss: 0.4047 - val_accuracy: 0.8910\n",
      "Epoch 123/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4119 - accuracy: 0.8834 - val_loss: 0.4031 - val_accuracy: 0.8925\n",
      "Epoch 124/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4091 - accuracy: 0.8823 - val_loss: 0.4001 - val_accuracy: 0.8915\n",
      "Epoch 125/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.4068 - accuracy: 0.8835 - val_loss: 0.4005 - val_accuracy: 0.8890\n",
      "Epoch 126/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4058 - accuracy: 0.8836 - val_loss: 0.3951 - val_accuracy: 0.8950\n",
      "Epoch 127/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4025 - accuracy: 0.8841 - val_loss: 0.3947 - val_accuracy: 0.8890\n",
      "Epoch 128/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4016 - accuracy: 0.8855 - val_loss: 0.3928 - val_accuracy: 0.8940\n",
      "Epoch 129/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3976 - accuracy: 0.8842 - val_loss: 0.3886 - val_accuracy: 0.8965\n",
      "Epoch 130/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3954 - accuracy: 0.8874 - val_loss: 0.3867 - val_accuracy: 0.8925\n",
      "Epoch 131/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3938 - accuracy: 0.8870 - val_loss: 0.3857 - val_accuracy: 0.8925\n",
      "Epoch 132/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3922 - accuracy: 0.8875 - val_loss: 0.3823 - val_accuracy: 0.8975\n",
      "Epoch 133/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3902 - accuracy: 0.8859 - val_loss: 0.3795 - val_accuracy: 0.8965\n",
      "Epoch 134/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3880 - accuracy: 0.8882 - val_loss: 0.3789 - val_accuracy: 0.8970\n",
      "Epoch 135/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3855 - accuracy: 0.8903 - val_loss: 0.3792 - val_accuracy: 0.8945\n",
      "Epoch 136/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3843 - accuracy: 0.8891 - val_loss: 0.3740 - val_accuracy: 0.8980\n",
      "Epoch 137/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3812 - accuracy: 0.8906 - val_loss: 0.3726 - val_accuracy: 0.8955\n",
      "Epoch 138/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3798 - accuracy: 0.8913 - val_loss: 0.3707 - val_accuracy: 0.8985\n",
      "Epoch 139/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3778 - accuracy: 0.8914 - val_loss: 0.3704 - val_accuracy: 0.9015\n",
      "Epoch 140/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3763 - accuracy: 0.8907 - val_loss: 0.3670 - val_accuracy: 0.8990\n",
      "Epoch 141/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3745 - accuracy: 0.8904 - val_loss: 0.3654 - val_accuracy: 0.9000\n",
      "Epoch 142/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3727 - accuracy: 0.8911 - val_loss: 0.3646 - val_accuracy: 0.9020\n",
      "Epoch 143/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3709 - accuracy: 0.8903 - val_loss: 0.3603 - val_accuracy: 0.9010\n",
      "Epoch 144/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3685 - accuracy: 0.8925 - val_loss: 0.3594 - val_accuracy: 0.8995\n",
      "Epoch 145/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3672 - accuracy: 0.8911 - val_loss: 0.3576 - val_accuracy: 0.8995\n",
      "Epoch 146/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3651 - accuracy: 0.8944 - val_loss: 0.3560 - val_accuracy: 0.9030\n",
      "Epoch 147/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3630 - accuracy: 0.8947 - val_loss: 0.3536 - val_accuracy: 0.9015\n",
      "Epoch 148/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3623 - accuracy: 0.8945 - val_loss: 0.3520 - val_accuracy: 0.9020\n",
      "Epoch 149/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3602 - accuracy: 0.8929 - val_loss: 0.3526 - val_accuracy: 0.9045\n",
      "Epoch 150/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3584 - accuracy: 0.8963 - val_loss: 0.3500 - val_accuracy: 0.9050\n",
      "Epoch 151/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3574 - accuracy: 0.8959 - val_loss: 0.3470 - val_accuracy: 0.9020\n",
      "Epoch 152/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3555 - accuracy: 0.8967 - val_loss: 0.3463 - val_accuracy: 0.9035\n",
      "Epoch 153/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3538 - accuracy: 0.8971 - val_loss: 0.3445 - val_accuracy: 0.9025\n",
      "Epoch 154/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3520 - accuracy: 0.8967 - val_loss: 0.3448 - val_accuracy: 0.9035\n",
      "Epoch 155/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3508 - accuracy: 0.8981 - val_loss: 0.3420 - val_accuracy: 0.9060\n",
      "Epoch 156/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3491 - accuracy: 0.8961 - val_loss: 0.3410 - val_accuracy: 0.9060\n",
      "Epoch 157/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3482 - accuracy: 0.8970 - val_loss: 0.3385 - val_accuracy: 0.9050\n",
      "Epoch 158/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3466 - accuracy: 0.8967 - val_loss: 0.3363 - val_accuracy: 0.9035\n",
      "Epoch 159/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3448 - accuracy: 0.8996 - val_loss: 0.3357 - val_accuracy: 0.9035\n",
      "Epoch 160/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3443 - accuracy: 0.8995 - val_loss: 0.3342 - val_accuracy: 0.9030\n",
      "Epoch 161/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3421 - accuracy: 0.8985 - val_loss: 0.3314 - val_accuracy: 0.9040\n",
      "Epoch 162/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3404 - accuracy: 0.8984 - val_loss: 0.3304 - val_accuracy: 0.9045\n",
      "Epoch 163/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3386 - accuracy: 0.9006 - val_loss: 0.3292 - val_accuracy: 0.9090\n",
      "Epoch 164/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3375 - accuracy: 0.9003 - val_loss: 0.3281 - val_accuracy: 0.9055\n",
      "Epoch 165/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3358 - accuracy: 0.8980 - val_loss: 0.3272 - val_accuracy: 0.9045\n",
      "Epoch 166/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3347 - accuracy: 0.9013 - val_loss: 0.3251 - val_accuracy: 0.9050\n",
      "Epoch 167/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3333 - accuracy: 0.9013 - val_loss: 0.3241 - val_accuracy: 0.9065\n",
      "Epoch 168/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3320 - accuracy: 0.9020 - val_loss: 0.3236 - val_accuracy: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3305 - accuracy: 0.9021 - val_loss: 0.3238 - val_accuracy: 0.9095\n",
      "Epoch 170/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3290 - accuracy: 0.9028 - val_loss: 0.3232 - val_accuracy: 0.9060\n",
      "Epoch 171/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3287 - accuracy: 0.9041 - val_loss: 0.3191 - val_accuracy: 0.9060\n",
      "Epoch 172/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3270 - accuracy: 0.9021 - val_loss: 0.3197 - val_accuracy: 0.9065\n",
      "Epoch 173/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3264 - accuracy: 0.9031 - val_loss: 0.3156 - val_accuracy: 0.9065\n",
      "Epoch 174/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3245 - accuracy: 0.9040 - val_loss: 0.3151 - val_accuracy: 0.9070\n",
      "Epoch 175/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3231 - accuracy: 0.9049 - val_loss: 0.3140 - val_accuracy: 0.9070\n",
      "Epoch 176/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3222 - accuracy: 0.9044 - val_loss: 0.3120 - val_accuracy: 0.9065\n",
      "Epoch 177/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3205 - accuracy: 0.9045 - val_loss: 0.3146 - val_accuracy: 0.9070\n",
      "Epoch 178/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3195 - accuracy: 0.9043 - val_loss: 0.3111 - val_accuracy: 0.9085\n",
      "Epoch 179/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3184 - accuracy: 0.9061 - val_loss: 0.3097 - val_accuracy: 0.9075\n",
      "Epoch 180/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3173 - accuracy: 0.9045 - val_loss: 0.3086 - val_accuracy: 0.9060\n",
      "Epoch 181/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3159 - accuracy: 0.9064 - val_loss: 0.3075 - val_accuracy: 0.9085\n",
      "Epoch 182/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3147 - accuracy: 0.9066 - val_loss: 0.3060 - val_accuracy: 0.9115\n",
      "Epoch 183/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3136 - accuracy: 0.9055 - val_loss: 0.3048 - val_accuracy: 0.9070\n",
      "Epoch 184/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3128 - accuracy: 0.9069 - val_loss: 0.3042 - val_accuracy: 0.9100\n",
      "Epoch 185/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3118 - accuracy: 0.9071 - val_loss: 0.3036 - val_accuracy: 0.9110\n",
      "Epoch 186/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3108 - accuracy: 0.9072 - val_loss: 0.3017 - val_accuracy: 0.9100\n",
      "Epoch 187/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3095 - accuracy: 0.9080 - val_loss: 0.2998 - val_accuracy: 0.9105\n",
      "Epoch 188/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3079 - accuracy: 0.9080 - val_loss: 0.2992 - val_accuracy: 0.9095\n",
      "Epoch 189/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3069 - accuracy: 0.9084 - val_loss: 0.2981 - val_accuracy: 0.9095\n",
      "Epoch 190/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3068 - accuracy: 0.9076 - val_loss: 0.2983 - val_accuracy: 0.9065\n",
      "Epoch 191/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3054 - accuracy: 0.9085 - val_loss: 0.2982 - val_accuracy: 0.9105\n",
      "Epoch 192/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3043 - accuracy: 0.9106 - val_loss: 0.2963 - val_accuracy: 0.9130\n",
      "Epoch 193/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3033 - accuracy: 0.9103 - val_loss: 0.2955 - val_accuracy: 0.9105\n",
      "Epoch 194/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3020 - accuracy: 0.9097 - val_loss: 0.2929 - val_accuracy: 0.9115\n",
      "Epoch 195/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3013 - accuracy: 0.9107 - val_loss: 0.2931 - val_accuracy: 0.9115\n",
      "Epoch 196/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.3001 - accuracy: 0.9106 - val_loss: 0.2919 - val_accuracy: 0.9100\n",
      "Epoch 197/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2991 - accuracy: 0.9107 - val_loss: 0.2904 - val_accuracy: 0.9110\n",
      "Epoch 198/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2981 - accuracy: 0.9121 - val_loss: 0.2901 - val_accuracy: 0.9105\n",
      "Epoch 199/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2975 - accuracy: 0.9133 - val_loss: 0.2891 - val_accuracy: 0.9115\n",
      "Epoch 200/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2959 - accuracy: 0.9121 - val_loss: 0.2919 - val_accuracy: 0.9145\n",
      "Epoch 201/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2955 - accuracy: 0.9136 - val_loss: 0.2865 - val_accuracy: 0.9105\n",
      "Epoch 202/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2945 - accuracy: 0.9126 - val_loss: 0.2865 - val_accuracy: 0.9155\n",
      "Epoch 203/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2935 - accuracy: 0.9139 - val_loss: 0.2848 - val_accuracy: 0.9140\n",
      "Epoch 204/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2927 - accuracy: 0.9129 - val_loss: 0.2848 - val_accuracy: 0.9115\n",
      "Epoch 205/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2917 - accuracy: 0.9126 - val_loss: 0.2823 - val_accuracy: 0.9145\n",
      "Epoch 206/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2909 - accuracy: 0.9145 - val_loss: 0.2844 - val_accuracy: 0.9165\n",
      "Epoch 207/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2900 - accuracy: 0.9141 - val_loss: 0.2819 - val_accuracy: 0.9175\n",
      "Epoch 208/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2894 - accuracy: 0.9146 - val_loss: 0.2814 - val_accuracy: 0.9160\n",
      "Epoch 209/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2883 - accuracy: 0.9144 - val_loss: 0.2800 - val_accuracy: 0.9175\n",
      "Epoch 210/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2871 - accuracy: 0.9154 - val_loss: 0.2805 - val_accuracy: 0.9205\n",
      "Epoch 211/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2861 - accuracy: 0.9155 - val_loss: 0.2811 - val_accuracy: 0.9170\n",
      "Epoch 212/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2861 - accuracy: 0.9158 - val_loss: 0.2781 - val_accuracy: 0.9180\n",
      "Epoch 213/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2849 - accuracy: 0.9147 - val_loss: 0.2787 - val_accuracy: 0.9205\n",
      "Epoch 214/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.92 - 0s 6us/step - loss: 0.2843 - accuracy: 0.9159 - val_loss: 0.2766 - val_accuracy: 0.9150\n",
      "Epoch 215/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2833 - accuracy: 0.9168 - val_loss: 0.2758 - val_accuracy: 0.9195\n",
      "Epoch 216/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2821 - accuracy: 0.9169 - val_loss: 0.2760 - val_accuracy: 0.9175\n",
      "Epoch 217/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2820 - accuracy: 0.9164 - val_loss: 0.2771 - val_accuracy: 0.9225\n",
      "Epoch 218/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2811 - accuracy: 0.9168 - val_loss: 0.2732 - val_accuracy: 0.9170\n",
      "Epoch 219/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2807 - accuracy: 0.9156 - val_loss: 0.2728 - val_accuracy: 0.9215\n",
      "Epoch 220/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2799 - accuracy: 0.9166 - val_loss: 0.2727 - val_accuracy: 0.9215\n",
      "Epoch 221/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2786 - accuracy: 0.9165 - val_loss: 0.2709 - val_accuracy: 0.9200\n",
      "Epoch 222/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2776 - accuracy: 0.9179 - val_loss: 0.2704 - val_accuracy: 0.9175\n",
      "Epoch 223/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2765 - accuracy: 0.9181 - val_loss: 0.2701 - val_accuracy: 0.9220\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2763 - accuracy: 0.9184 - val_loss: 0.2691 - val_accuracy: 0.9195\n",
      "Epoch 225/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2753 - accuracy: 0.9190 - val_loss: 0.2686 - val_accuracy: 0.9175\n",
      "Epoch 226/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2747 - accuracy: 0.9183 - val_loss: 0.2682 - val_accuracy: 0.9225\n",
      "Epoch 227/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2739 - accuracy: 0.9199 - val_loss: 0.2663 - val_accuracy: 0.9215\n",
      "Epoch 228/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2737 - accuracy: 0.9194 - val_loss: 0.2659 - val_accuracy: 0.9215\n",
      "Epoch 229/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2728 - accuracy: 0.9194 - val_loss: 0.2666 - val_accuracy: 0.9210\n",
      "Epoch 230/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2726 - accuracy: 0.9199 - val_loss: 0.2649 - val_accuracy: 0.9215\n",
      "Epoch 231/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2714 - accuracy: 0.9197 - val_loss: 0.2649 - val_accuracy: 0.9220\n",
      "Epoch 232/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2705 - accuracy: 0.9200 - val_loss: 0.2654 - val_accuracy: 0.9285\n",
      "Epoch 233/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2698 - accuracy: 0.9211 - val_loss: 0.2624 - val_accuracy: 0.9190\n",
      "Epoch 234/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2690 - accuracy: 0.9208 - val_loss: 0.2625 - val_accuracy: 0.9235\n",
      "Epoch 235/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2684 - accuracy: 0.9200 - val_loss: 0.2609 - val_accuracy: 0.9220\n",
      "Epoch 236/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2681 - accuracy: 0.9216 - val_loss: 0.2613 - val_accuracy: 0.9205\n",
      "Epoch 237/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2672 - accuracy: 0.9224 - val_loss: 0.2595 - val_accuracy: 0.9205\n",
      "Epoch 238/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2673 - accuracy: 0.9224 - val_loss: 0.2597 - val_accuracy: 0.9295\n",
      "Epoch 239/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2657 - accuracy: 0.9222 - val_loss: 0.2607 - val_accuracy: 0.9250\n",
      "Epoch 240/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2658 - accuracy: 0.9218 - val_loss: 0.2584 - val_accuracy: 0.9270\n",
      "Epoch 241/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2640 - accuracy: 0.9235 - val_loss: 0.2579 - val_accuracy: 0.9320\n",
      "Epoch 242/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2641 - accuracy: 0.9219 - val_loss: 0.2561 - val_accuracy: 0.9250\n",
      "Epoch 243/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2635 - accuracy: 0.9222 - val_loss: 0.2553 - val_accuracy: 0.9270\n",
      "Epoch 244/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2625 - accuracy: 0.9225 - val_loss: 0.2566 - val_accuracy: 0.9320\n",
      "Epoch 245/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2621 - accuracy: 0.9235 - val_loss: 0.2572 - val_accuracy: 0.9260\n",
      "Epoch 246/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2618 - accuracy: 0.9221 - val_loss: 0.2563 - val_accuracy: 0.9255\n",
      "Epoch 247/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2610 - accuracy: 0.9244 - val_loss: 0.2554 - val_accuracy: 0.9315\n",
      "Epoch 248/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2600 - accuracy: 0.9236 - val_loss: 0.2552 - val_accuracy: 0.9310\n",
      "Epoch 249/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2598 - accuracy: 0.9236 - val_loss: 0.2539 - val_accuracy: 0.9310\n",
      "Epoch 250/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2585 - accuracy: 0.9233 - val_loss: 0.2534 - val_accuracy: 0.9250\n",
      "Epoch 251/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2586 - accuracy: 0.9239 - val_loss: 0.2521 - val_accuracy: 0.9310\n",
      "Epoch 252/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2574 - accuracy: 0.9254 - val_loss: 0.2518 - val_accuracy: 0.9275\n",
      "Epoch 253/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2578 - accuracy: 0.9230 - val_loss: 0.2512 - val_accuracy: 0.9285\n",
      "Epoch 254/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2561 - accuracy: 0.9259 - val_loss: 0.2512 - val_accuracy: 0.9280\n",
      "Epoch 255/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2558 - accuracy: 0.9254 - val_loss: 0.2496 - val_accuracy: 0.9335\n",
      "Epoch 256/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2556 - accuracy: 0.9246 - val_loss: 0.2503 - val_accuracy: 0.9330\n",
      "Epoch 257/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2546 - accuracy: 0.9256 - val_loss: 0.2492 - val_accuracy: 0.9315\n",
      "Epoch 258/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2542 - accuracy: 0.9249 - val_loss: 0.2496 - val_accuracy: 0.9300\n",
      "Epoch 259/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2538 - accuracy: 0.9254 - val_loss: 0.2496 - val_accuracy: 0.9265\n",
      "Epoch 260/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2531 - accuracy: 0.9275 - val_loss: 0.2487 - val_accuracy: 0.9290\n",
      "Epoch 261/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2522 - accuracy: 0.9268 - val_loss: 0.2487 - val_accuracy: 0.9300\n",
      "Epoch 262/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2520 - accuracy: 0.9260 - val_loss: 0.2468 - val_accuracy: 0.9330\n",
      "Epoch 263/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2511 - accuracy: 0.9275 - val_loss: 0.2456 - val_accuracy: 0.9325\n",
      "Epoch 264/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2515 - accuracy: 0.9269 - val_loss: 0.2465 - val_accuracy: 0.9315\n",
      "Epoch 265/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2510 - accuracy: 0.9266 - val_loss: 0.2458 - val_accuracy: 0.9320\n",
      "Epoch 266/300\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2501 - accuracy: 0.9268 - val_loss: 0.2433 - val_accuracy: 0.9335\n",
      "Epoch 267/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2494 - accuracy: 0.9286 - val_loss: 0.2441 - val_accuracy: 0.9320\n",
      "Epoch 268/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2489 - accuracy: 0.9274 - val_loss: 0.2433 - val_accuracy: 0.9325\n",
      "Epoch 269/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2487 - accuracy: 0.9268 - val_loss: 0.2441 - val_accuracy: 0.9305\n",
      "Epoch 270/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2475 - accuracy: 0.9280 - val_loss: 0.2430 - val_accuracy: 0.9320\n",
      "Epoch 271/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2470 - accuracy: 0.9286 - val_loss: 0.2415 - val_accuracy: 0.9335\n",
      "Epoch 272/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2467 - accuracy: 0.9271 - val_loss: 0.2428 - val_accuracy: 0.9300\n",
      "Epoch 273/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2471 - accuracy: 0.9285 - val_loss: 0.2415 - val_accuracy: 0.9305\n",
      "Epoch 274/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2458 - accuracy: 0.9290 - val_loss: 0.2406 - val_accuracy: 0.9320\n",
      "Epoch 275/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2454 - accuracy: 0.9280 - val_loss: 0.2432 - val_accuracy: 0.9320\n",
      "Epoch 276/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2452 - accuracy: 0.9290 - val_loss: 0.2403 - val_accuracy: 0.9315\n",
      "Epoch 277/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2445 - accuracy: 0.9285 - val_loss: 0.2404 - val_accuracy: 0.9330\n",
      "Epoch 278/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2439 - accuracy: 0.9285 - val_loss: 0.2407 - val_accuracy: 0.9335\n",
      "Epoch 279/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2434 - accuracy: 0.9289 - val_loss: 0.2376 - val_accuracy: 0.9340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2430 - accuracy: 0.9279 - val_loss: 0.2381 - val_accuracy: 0.9320\n",
      "Epoch 281/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2424 - accuracy: 0.9304 - val_loss: 0.2369 - val_accuracy: 0.9355\n",
      "Epoch 282/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2429 - accuracy: 0.9298 - val_loss: 0.2391 - val_accuracy: 0.9335\n",
      "Epoch 283/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2417 - accuracy: 0.9311 - val_loss: 0.2375 - val_accuracy: 0.9350\n",
      "Epoch 284/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2416 - accuracy: 0.9287 - val_loss: 0.2371 - val_accuracy: 0.9335\n",
      "Epoch 285/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2406 - accuracy: 0.9302 - val_loss: 0.2370 - val_accuracy: 0.9330\n",
      "Epoch 286/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2405 - accuracy: 0.9298 - val_loss: 0.2352 - val_accuracy: 0.9345\n",
      "Epoch 287/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2401 - accuracy: 0.9310 - val_loss: 0.2373 - val_accuracy: 0.9325\n",
      "Epoch 288/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2391 - accuracy: 0.9301 - val_loss: 0.2343 - val_accuracy: 0.9315\n",
      "Epoch 289/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2383 - accuracy: 0.9311 - val_loss: 0.2369 - val_accuracy: 0.9340\n",
      "Epoch 290/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2390 - accuracy: 0.9299 - val_loss: 0.2346 - val_accuracy: 0.9340\n",
      "Epoch 291/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2381 - accuracy: 0.9314 - val_loss: 0.2322 - val_accuracy: 0.9360\n",
      "Epoch 292/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2379 - accuracy: 0.9302 - val_loss: 0.2336 - val_accuracy: 0.9335\n",
      "Epoch 293/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2375 - accuracy: 0.9312 - val_loss: 0.2330 - val_accuracy: 0.9350\n",
      "Epoch 294/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2368 - accuracy: 0.9315 - val_loss: 0.2326 - val_accuracy: 0.9355\n",
      "Epoch 295/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2365 - accuracy: 0.9315 - val_loss: 0.2325 - val_accuracy: 0.9325\n",
      "Epoch 296/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2362 - accuracy: 0.9301 - val_loss: 0.2330 - val_accuracy: 0.9320\n",
      "Epoch 297/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2356 - accuracy: 0.9320 - val_loss: 0.2316 - val_accuracy: 0.9355\n",
      "Epoch 298/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2347 - accuracy: 0.9304 - val_loss: 0.2292 - val_accuracy: 0.9350\n",
      "Epoch 299/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2346 - accuracy: 0.9337 - val_loss: 0.2300 - val_accuracy: 0.9350\n",
      "Epoch 300/300\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2340 - accuracy: 0.9319 - val_loss: 0.2306 - val_accuracy: 0.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4089c4e910>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=300,\n",
    "          batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 10us/step\n",
      "\n",
      "Testing loss: 0.25, acc: 0.93%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('\\nTesting loss: %.2f, acc: %.2f%%'%(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:\n",
      "[5 8 8 ... 6 8 5]\n",
      "True Label:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The predict_classes function outputs the highest probability class\n",
    "# according to the trained classifier for each input example.\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "print(\"predicted:\")\n",
    "print(predicted_classes)\n",
    "print(\"True Label:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
